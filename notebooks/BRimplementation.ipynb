{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4b971e-fff9-4afe-be5e-5223683d363a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.data import create_dataloaders, denormalize\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "188e2a6f-92da-4113-a6b8-75a4f5785be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading background images for BR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 100/100 [00:00<00:00, 1721.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 100 background images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load counterfactual backgrounds\n",
    "cf_image_dir = '../data/counterfactuals/val_counterfactual/images'\n",
    "background_images = []\n",
    "\n",
    "print(\"Loading background images for BR...\")\n",
    "cf_files = sorted([f for f in os.listdir(cf_image_dir) if f.endswith('.jpg')])[:100]  # Use first 100\n",
    "\n",
    "for cf_file in tqdm(cf_files):\n",
    "    cf_path = os.path.join(cf_image_dir, cf_file)\n",
    "    img = Image.open(cf_path).convert('RGB')\n",
    "    img_arr = np.array(img)\n",
    "    background_images.append(img_arr)\n",
    "\n",
    "print(f\"✓ Loaded {len(background_images)} background images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7f3dc22-4190-46d1-92e8-67d015f2725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BR transform initialized for p=[0.25, 0.50, 0.75, 1.0]\n"
     ]
    }
   ],
   "source": [
    "class BackgroundRandomizationTransform:\n",
    "    \"\"\"\n",
    "    Apply background randomization during training\n",
    "    Swaps background with random background from pool\n",
    "    \"\"\"\n",
    "    def __init__(self, background_images, p=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            background_images: List of background images (numpy arrays)\n",
    "            p: Probability of applying background randomization\n",
    "        \"\"\"\n",
    "        self.background_images = background_images\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, image_tensor, mask_tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_tensor: PIL Image or torch tensor\n",
    "            mask_tensor: Mask tensor (1=foreground, 0=background)\n",
    "        \n",
    "        Returns:\n",
    "            image_tensor: Possibly augmented image\n",
    "        \"\"\"\n",
    "        if np.random.random() > self.p:\n",
    "            return image_tensor  # Don't apply BR\n",
    "        \n",
    "        # Convert to numpy if needed\n",
    "        if isinstance(image_tensor, Image.Image):\n",
    "            image_np = np.array(image_tensor)\n",
    "        else:\n",
    "            image_np = image_tensor\n",
    "        \n",
    "        # Ensure mask is 2D\n",
    "        if isinstance(mask_tensor, torch.Tensor):\n",
    "            mask_np = mask_tensor.numpy() if mask_tensor.dim() == 2 else mask_tensor.numpy()\n",
    "        else:\n",
    "            mask_np = mask_tensor\n",
    "        \n",
    "        # Get random background\n",
    "        bg_idx = np.random.randint(0, len(self.background_images))\n",
    "        bg_image = self.background_images[bg_idx]\n",
    "        \n",
    "        # Resize background to match image size\n",
    "        h, w = image_np.shape[:2]\n",
    "        bg_resized = cv2.resize(bg_image, (w, h))\n",
    "        \n",
    "        # Extract foreground\n",
    "        mask_3ch = np.stack([mask_np, mask_np, mask_np], axis=-1)\n",
    "        foreground = image_np * mask_3ch\n",
    "        background = bg_resized * (1 - mask_3ch)\n",
    "        \n",
    "        # Combine\n",
    "        augmented = (foreground + background).astype(np.uint8)\n",
    "        \n",
    "        return Image.fromarray(augmented)\n",
    "\n",
    "# Create BR transforms for different probabilities\n",
    "br_transforms = {}\n",
    "for p in [0.25, 0.50, 0.75]:\n",
    "    br_transforms[p] = BackgroundRandomizationTransform(background_images, p=p)\n",
    "\n",
    "print(\"✓ BR transform initialized for p=[0.25, 0.50, 0.75, 1.0]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5700ee19-aba9-45c3-8492-cd496100821f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ BR-augmented dataset class created\n"
     ]
    }
   ],
   "source": [
    "class OxfordPetDatasetWithBR:\n",
    "    \"\"\"\n",
    "    Wrapper that applies BR to base dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, base_dataset, br_transform=None):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.br_transform = br_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.base_dataset[idx]\n",
    "        \n",
    "        # Apply BR if transform provided\n",
    "        if self.br_transform is not None:\n",
    "            # Reconstruct image from original_image\n",
    "            image_pil = Image.fromarray(sample['original_image'])\n",
    "            mask = sample['original_mask']\n",
    "            \n",
    "            # Apply BR\n",
    "            image_augmented = self.br_transform(image_pil, mask)\n",
    "            \n",
    "            # Apply standard transforms\n",
    "            from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "            IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "            IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "            \n",
    "            transform = Compose([\n",
    "                Resize((224, 224)),\n",
    "                ToTensor(),\n",
    "                Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "            ])\n",
    "            \n",
    "            image = transform(image_augmented)\n",
    "        else:\n",
    "            image = sample['image']\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'mask': sample['mask'],\n",
    "            'label': sample['label']\n",
    "        }\n",
    "\n",
    "print(\"✓ BR-augmented dataset class created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbebd196-c91d-483e-b88c-11ce2e10ae4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BR variants to train:\n",
      "  br_p025: BR (p=0.25)\n",
      "  br_p050: BR (p=0.50)\n",
      "  br_p075: BR (p=0.75)\n"
     ]
    }
   ],
   "source": [
    "# Base config (same as baseline)\n",
    "base_config = {\n",
    "    'training': {\n",
    "        'epochs': 20,\n",
    "        'batch_size': 32,\n",
    "        'num_workers': 4,\n",
    "        'learning_rate': 3e-4,\n",
    "        'weight_decay': 0.01,\n",
    "        'optimizer': 'AdamW',\n",
    "    },\n",
    "    'scheduler': {\n",
    "        'type': 'cosine',\n",
    "        'T_max': 30,\n",
    "    },\n",
    "    'data': {\n",
    "        'image_size': 224,\n",
    "        'data_root': '../data/raw',\n",
    "        'split_metadata_path': '../data/processed/split_metadata.json',\n",
    "    },\n",
    "    'device': 'mps' if torch.backends.mps.is_available() else 'cpu',\n",
    "    'checkpoint': {\n",
    "        'save_every': 5,\n",
    "        'save_dir': None,  # Will be set per variant\n",
    "    },\n",
    "}\n",
    "\n",
    "# Define BR variants\n",
    "br_variants = {\n",
    "    'br_p025': {'p': 0.25, 'name': 'BR (p=0.25)'},\n",
    "    'br_p050': {'p': 0.50, 'name': 'BR (p=0.50)'},\n",
    "    'br_p075': {'p': 0.75, 'name': 'BR (p=0.75)'},\n",
    "}\n",
    "\n",
    "print(\"BR variants to train:\")\n",
    "for key, config in br_variants.items():\n",
    "    print(f\"  {key}: {config['name']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfefad4b-c14a-4575-a0f3-84814fb1e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training function defined\n"
     ]
    }
   ],
   "source": [
    "def train_br_variant(variant_key, br_config, background_images, base_config):\n",
    "    \"\"\"\n",
    "    Train BR model with specific probability\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING: {br_config['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader, dataset = create_dataloaders(\n",
    "        data_root=base_config['data']['data_root'],\n",
    "        split_metadata_path=base_config['data']['split_metadata_path'],\n",
    "        batch_size=base_config['training']['batch_size'],\n",
    "        num_workers=base_config['training']['num_workers'],\n",
    "        img_size=base_config['data']['image_size'],\n",
    "        pin_memory=False\n",
    "    )\n",
    "    \n",
    "    # Create BR transform\n",
    "    br_transform = BackgroundRandomizationTransform(background_images, p=br_config['p'])\n",
    "    \n",
    "    # Get raw dataset for applying BR\n",
    "    train_raw = train_loader.dataset\n",
    "    \n",
    "    # Create model\n",
    "    model = models.resnet50(weights='DEFAULT')\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 37)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=base_config['training']['learning_rate'],\n",
    "        weight_decay=base_config['training']['weight_decay']\n",
    "    )\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=base_config['scheduler']['T_max'], eta_min=1e-6)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Checkpoint directory\n",
    "    checkpoint_dir = f\"../models/checkpoints/{variant_key}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Training loop\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'learning_rate': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for epoch in range(base_config['training']['epochs']):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader), \n",
    "                   desc=f'Epoch {epoch+1}/{base_config[\"training\"][\"epochs\"]} [TRAIN]')\n",
    "        \n",
    "        for batch_idx, batch in pbar:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Apply BR to batch\n",
    "            images_br = []\n",
    "            for i, img in enumerate(images):\n",
    "                # Get corresponding original image for mask\n",
    "                sample_idx = batch_idx * base_config['training']['batch_size'] + i\n",
    "                if sample_idx < len(train_raw):\n",
    "                    orig_sample = train_raw[sample_idx]\n",
    "                    mask = orig_sample['mask'].numpy()\n",
    "                    \n",
    "                    # Denormalize image\n",
    "                    img_np = img.cpu().numpy()\n",
    "                    mean = np.array([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n",
    "                    std = np.array([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n",
    "                    img_denorm = (img_np * std + mean * 255).transpose(1, 2, 0).astype(np.uint8)\n",
    "                    \n",
    "                    # Apply BR\n",
    "                    img_pil = Image.fromarray(img_denorm)\n",
    "                    img_br = br_transform(img_pil, mask)\n",
    "                    \n",
    "                    # Re-normalize\n",
    "                    img_br_arr = np.array(img_br).astype(np.float32) / 255.0\n",
    "                    img_br_tensor = torch.from_numpy(img_br_arr.transpose(2, 0, 1))\n",
    "                    img_br_tensor = (img_br_tensor - torch.from_numpy(mean)) / torch.from_numpy(std)\n",
    "                    images_br.append(img_br_tensor)\n",
    "                else:\n",
    "                    images_br.append(img.cpu())\n",
    "            \n",
    "            images_br = torch.stack(images_br).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images_br)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            \n",
    "            acc = train_correct / train_total\n",
    "            avg_loss = train_loss / (batch_idx + 1)\n",
    "            pbar.set_postfix({'loss': f'{avg_loss:.4f}', 'acc': f'{acc*100:.1f}%'})\n",
    "        \n",
    "        epoch_train_loss = train_loss / len(train_loader)\n",
    "        epoch_train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        pbar_val = tqdm(val_loader, desc=f'Epoch {epoch+1}/{base_config[\"training\"][\"epochs\"]} [VAL]')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in pbar_val:\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                \n",
    "                acc = val_correct / val_total\n",
    "                avg_loss = val_loss / (val_total // base_config['training']['batch_size'] + 1)\n",
    "                pbar_val.set_postfix({'loss': f'{avg_loss:.4f}', 'acc': f'{acc*100:.1f}%'})\n",
    "        \n",
    "        epoch_val_loss = val_loss / len(val_loader)\n",
    "        epoch_val_acc = val_correct / val_total\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups['lr']\n",
    "        \n",
    "        # Record history\n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['learning_rate'].append(current_lr)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{base_config['training']['epochs']}\")\n",
    "        print(f\"  Train Loss: {epoch_train_loss:.4f} | Train Acc: {epoch_train_acc*100:.1f}%\")\n",
    "        print(f\"  Val Loss:   {epoch_val_loss:.4f} | Val Acc:   {epoch_val_acc*100:.1f}%\")\n",
    "        print(f\"  LR: {current_lr:.2e}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % base_config['checkpoint']['save_every'] == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'resnet50_epoch_{epoch+1}.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'history': history\n",
    "            }, checkpoint_path)\n",
    "            print(f\"  ✓ Checkpoint saved\")\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            best_path = os.path.join(checkpoint_dir, 'resnet50_best.pth')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'history': history,\n",
    "                'config': {**base_config, 'br_p': br_config['p']}\n",
    "            }, best_path)\n",
    "            print(f\"  ✓ Best model saved\")\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    total_time = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"TRAINING COMPLETE: {br_config['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total time: {total_time/3600:.1f} hours\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save training history\n",
    "    history_csv_path = os.path.join(checkpoint_dir, 'training_history.csv')\n",
    "    with open(history_csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['epoch', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'lr'])\n",
    "        for epoch in range(len(history['train_loss'])):\n",
    "            writer.writerow([\n",
    "                epoch + 1,\n",
    "                history['train_loss'][epoch],\n",
    "                history['train_acc'][epoch],\n",
    "                history['val_loss'][epoch],\n",
    "                history['val_acc'][epoch],\n",
    "                history['learning_rate'][epoch]\n",
    "            ])\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"✓ Training function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a83e31ac-4d2e-4463-8635-a27a9c079d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING: BR (p=0.25)\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m br_histories = {}\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m variant_key, br_config \u001b[38;5;129;01min\u001b[39;00m br_variants.items():\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     history = \u001b[43mtrain_br_variant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariant_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbr_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     br_histories[variant_key] = history\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Save history\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mtrain_br_variant\u001b[39m\u001b[34m(variant_key, br_config, background_images, base_config)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m70\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Create dataloaders\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m train_loader, val_loader, dataset = \u001b[43mcreate_dataloaders\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_root\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit_metadata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msplit_metadata_path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_workers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Create BR transform\u001b[39;00m\n\u001b[32m     20\u001b[39m br_transform = BackgroundRandomizationTransform(background_images, p=br_config[\u001b[33m'\u001b[39m\u001b[33mp\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Spurious_correlation/notebooks/../src/data/dataloader.py:38\u001b[39m, in \u001b[36mcreate_dataloaders\u001b[39m\u001b[34m(data_root, split_metadata_path, batch_size, num_workers, img_size, pin_memory)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03mCreate train and validation dataloaders\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m \u001b[33;03m    dataset: Base OxfordIIITPet dataset\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Load base dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m dataset = \u001b[43mOxfordIIITPet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrainval\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_types\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msegmentation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     43\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Load split indices\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(split_metadata_path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Spurious_correlation/.venv/lib/python3.13/site-packages/torchvision/datasets/oxford_iiit_pet.py:70\u001b[39m, in \u001b[36mOxfordIIITPet.__init__\u001b[39m\u001b[34m(self, root, split, target_types, transforms, transform, target_transform, download)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m._download()\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._check_exists():\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataset not found. You can use download=True to download it\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     72\u001b[39m image_ids = []\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m._labels = []\n",
      "\u001b[31mRuntimeError\u001b[39m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "# Train each BR variant\n",
    "br_histories = {}\n",
    "\n",
    "for variant_key, br_config in br_variants.items():\n",
    "    history = train_br_variant(variant_key, br_config, background_images, base_config)\n",
    "    br_histories[variant_key] = history\n",
    "    \n",
    "    # Save history\n",
    "    history_path = f\"../experiments/results/metrics/{variant_key}_history.json\"\n",
    "    with open(history_path, 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ ALL BR VARIANTS TRAINED\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2241606c-c5e6-4d08-9f42-1d36b735b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "epochs_range = range(1, 31)\n",
    "\n",
    "# Plot 1: Validation Accuracy Comparison\n",
    "ax = axes[0, 0]\n",
    "for variant_key, history in br_histories.items():\n",
    "    p = br_variants[variant_key]['p']\n",
    "    ax.plot(epochs_range, np.array(history['val_acc'])*100, \n",
    "            marker='o', markersize=3, label=f\"BR (p={p})\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Validation Accuracy (%)')\n",
    "ax.set_title('Validation Accuracy: BR Variants')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Training Loss Comparison\n",
    "ax = axes[0, 1]\n",
    "for variant_key, history in br_histories.items():\n",
    "    p = br_variants[variant_key]['p']\n",
    "    ax.plot(epochs_range, history['train_loss'], \n",
    "            marker='s', markersize=3, label=f\"BR (p={p})\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Training Loss')\n",
    "ax.set_title('Training Loss: BR Variants')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Best Validation Accuracy\n",
    "ax = axes[1, 0]\n",
    "best_accs = [max(history['val_acc'])*100 for history in br_histories.values()]\n",
    "ps = [br_variants[k]['p'] for k in br_histories.keys()]\n",
    "ax.bar([f\"p={p}\" for p in ps], best_accs, color='steelblue', alpha=0.7)\n",
    "ax.set_ylabel('Best Validation Accuracy (%)')\n",
    "ax.set_title('Peak Performance by BR Probability')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Learning Rate Schedule\n",
    "ax = axes[1, 1]\n",
    "for variant_key, history in br_histories.items():\n",
    "    p = br_variants[variant_key]['p']\n",
    "    ax.plot(epochs_range, history['learning_rate'], \n",
    "            marker='o', markersize=2, label=f\"BR (p={p})\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.set_title('Learning Rate Schedule')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Day 6: Background Randomization Variants Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../experiments/results/plots/br_variants_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ BR variants comparison plot saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486d14d-aad9-46bd-8e24-d6cb2a60ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DAY 6 SUMMARY: BACKGROUND RANDOMIZATION TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "BR VARIANTS TRAINED:\n",
    "  4 probability variants: p=0.25, 0.50, 0.75, 1.0\n",
    "\n",
    "RESULTS COMPARISON:\n",
    "\"\"\"\n",
    "\n",
    "for variant_key, history in br_histories.items():\n",
    "    p = br_variants[variant_key]['p']\n",
    "    best_acc = max(history['val_acc']) * 100\n",
    "    best_epoch = np.argmax(history['val_acc']) + 1\n",
    "    final_acc = history['val_acc'][-1] * 100\n",
    "    \n",
    "    summary += f\"\\n  BR (p={p}):\"\n",
    "    summary += f\"\\n    Best Acc: {best_acc:.2f}% (Epoch {best_epoch})\"\n",
    "    summary += f\"\\n    Final Acc: {final_acc:.2f}%\"\n",
    "    summary += f\"\\n    Model saved to: ../models/checkpoints/br_p{int(p*100)}/resnet50_best.pth\"\n",
    "\n",
    "summary += f\"\"\"\n",
    "\n",
    "FILES CREATED:\n",
    "  ✓ 4 trained models (one per BR probability)\n",
    "  ✓ Training history CSV for each variant\n",
    "  ✓ Comparison plots\n",
    "  ✓ Model checkpoints every 5 epochs\n",
    "\n",
    "NEXT STEPS (Day 7):\n",
    "  1. Train Class-Balanced Fine-tuning (CBF) models\n",
    "  2. Day 8: Evaluate all models on counterfactuals\n",
    "  3. Compare BR vs CBF effectiveness\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\"*70)\n",
    "print(\"✅ DAY 6 COMPLETE - BR MODELS TRAINED\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
