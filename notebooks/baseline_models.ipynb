{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "afd46148-586b-4cb2-acaf-9d7a2bc9c0ff",
    "_uuid": "1db2f95e-f4f7-438a-95fa-5aa53287adbf",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:25.467916Z",
     "iopub.status.busy": "2025-11-08T10:30:25.467534Z",
     "iopub.status.idle": "2025-11-08T10:30:25.473783Z",
     "shell.execute_reply": "2025-11-08T10:30:25.473103Z",
     "shell.execute_reply.started": "2025-11-08T10:30:25.467882Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from datetime import datetime\n",
    "import timm\n",
    "\n",
    "\n",
    "# ---- Paths (adjust if needed) ----\n",
    "DATA_INPUT = '/kaggle/input'\n",
    "DATASET_NAME = 'spurious-correlation'\n",
    "DATASET_ROOT = os.path.join(DATA_INPUT, DATASET_NAME)\n",
    "\n",
    "# Candidate places where the Oxford data may live (handles extra nested dirs)\n",
    "CANDIDATE_OXFORD_ROOTS = [\n",
    "    os.path.join(DATASET_ROOT, 'oxford-iiit-pet'),\n",
    "    os.path.join(DATASET_ROOT, 'oxford-iiit-pet', 'oxford-iiit-pet'),\n",
    "    os.path.join(DATASET_ROOT, 'oxford_iiit_pet'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "4da639bc-cb88-4a80-951c-cfea75806dd0",
    "_uuid": "43b0ac81-5ce7-43b8-a822-0f949f81ca2c",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:25.475101Z",
     "iopub.status.busy": "2025-11-08T10:30:25.474875Z",
     "iopub.status.idle": "2025-11-08T10:30:25.490003Z",
     "shell.execute_reply": "2025-11-08T10:30:25.489204Z",
     "shell.execute_reply.started": "2025-11-08T10:30:25.475081Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_oxford_root():\n",
    "    for root in CANDIDATE_OXFORD_ROOTS:\n",
    "        images_dir = os.path.join(root, 'images')\n",
    "        ann_dir = os.path.join(root, 'annotations')\n",
    "        # also accept nested 'annotations/annotations'\n",
    "        alt_ann_dir = os.path.join(root, 'annotations', 'annotations')\n",
    "        if os.path.isdir(images_dir) and (os.path.isdir(ann_dir) or os.path.isdir(alt_ann_dir)):\n",
    "            return root\n",
    "    raise FileNotFoundError(\"Couldn't find oxford-iiit-pet root in expected candidate paths. \"\n",
    "                            f\"Checked: {CANDIDATE_OXFORD_ROOTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "3f9097b4-5e95-48e5-8a65-cfd7e90fccf0",
    "_uuid": "f17cb08b-159c-4aa6-8793-7cc9b69e1f47",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:26.581453Z",
     "iopub.status.busy": "2025-11-08T10:30:26.580671Z",
     "iopub.status.idle": "2025-11-08T10:30:26.591821Z",
     "shell.execute_reply": "2025-11-08T10:30:26.590987Z",
     "shell.execute_reply.started": "2025-11-08T10:30:26.581414Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Oxford root: /kaggle/input/spurious-correlation/oxford-iiit-pet/oxford-iiit-pet\n"
     ]
    }
   ],
   "source": [
    "OXFORD_ROOT = find_oxford_root()\n",
    "print(\"Using Oxford root:\", OXFORD_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "110f5d57-f802-4b08-afbf-3630a80dd63f",
    "_uuid": "362a2750-4e9f-4c47-934c-c3ad0e9b3f87",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:26.593529Z",
     "iopub.status.busy": "2025-11-08T10:30:26.593067Z",
     "iopub.status.idle": "2025-11-08T10:30:26.598564Z",
     "shell.execute_reply": "2025-11-08T10:30:26.597847Z",
     "shell.execute_reply.started": "2025-11-08T10:30:26.593504Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images dir: /kaggle/input/spurious-correlation/oxford-iiit-pet/oxford-iiit-pet/images\n",
      "Annotations dir: /kaggle/input/spurious-correlation/oxford-iiit-pet/oxford-iiit-pet/annotations\n"
     ]
    }
   ],
   "source": [
    "# canonical images/ and annotations/ (resolve nested annotations)\n",
    "IMAGES_DIR = os.path.join(OXFORD_ROOT, 'images')\n",
    "ANNOTATIONS_DIR = os.path.join(OXFORD_ROOT, 'annotations')\n",
    "\n",
    "if not os.path.isdir(ANNOTATIONS_DIR):\n",
    "    # fallback to nested 'annotations/annotations'\n",
    "    nested = os.path.join(OXFORD_ROOT, 'annotations', 'annotations')\n",
    "    if os.path.isdir(nested):\n",
    "        ANNOTATIONS_DIR = nested\n",
    "\n",
    "print(\"Images dir:\", IMAGES_DIR)\n",
    "print(\"Annotations dir:\", ANNOTATIONS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:26.668058Z",
     "iopub.status.busy": "2025-11-08T10:30:26.667428Z",
     "iopub.status.idle": "2025-11-08T10:30:26.676169Z",
     "shell.execute_reply": "2025-11-08T10:30:26.675482Z",
     "shell.execute_reply.started": "2025-11-08T10:30:26.668031Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found trainval.txt at: /kaggle/input/spurious-correlation/oxford-iiit-pet/oxford-iiit-pet/annotations/annotations/trainval.txt\n"
     ]
    }
   ],
   "source": [
    "# Try several likely locations for trainval.txt\n",
    "possible_trainval = [\n",
    "    os.path.join(ANNOTATIONS_DIR, 'trainval.txt'),\n",
    "    os.path.join(OXFORD_ROOT, 'trainval.txt'),\n",
    "    os.path.join(OXFORD_ROOT, 'annotations', 'trainval.txt'),\n",
    "    os.path.join(OXFORD_ROOT, 'annotations', 'annotations', 'trainval.txt'),\n",
    "]\n",
    "\n",
    "trainval_path = None\n",
    "\n",
    "# First check direct candidate paths\n",
    "for p in possible_trainval:\n",
    "    if os.path.isfile(p):\n",
    "        trainval_path = p\n",
    "        break\n",
    "\n",
    "# If still None, try recursive glob search\n",
    "if trainval_path is None:\n",
    "    matches = glob.glob(os.path.join(OXFORD_ROOT, '**', 'trainval.txt'), recursive=True)\n",
    "    if len(matches) > 0:\n",
    "        trainval_path = matches[0]\n",
    "\n",
    "# Final validation\n",
    "if trainval_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"trainval.txt not found.\\n\"\n",
    "        \"Tried the following paths:\\n\" +\n",
    "        \"\\n\".join(possible_trainval)\n",
    "    )\n",
    "\n",
    "print(\"✅ Found trainval.txt at:\", trainval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:26.677495Z",
     "iopub.status.busy": "2025-11-08T10:30:26.677304Z",
     "iopub.status.idle": "2025-11-08T10:30:26.692585Z",
     "shell.execute_reply": "2025-11-08T10:30:26.691853Z",
     "shell.execute_reply.started": "2025-11-08T10:30:26.677480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using IMAGES_DIR: /kaggle/input/spurious-correlation/oxford-iiit-pet/oxford-iiit-pet/images/images\n",
      "Using ANNOTATIONS_DIR: /kaggle/input/spurious-correlation/oxford-iiit-pet/oxford-iiit-pet/annotations/annotations\n"
     ]
    }
   ],
   "source": [
    "# Fix images directory if an extra nested 'images' folder exists\n",
    "if os.path.isdir(os.path.join(IMAGES_DIR, 'images')):\n",
    "    IMAGES_DIR = os.path.join(IMAGES_DIR, 'images')\n",
    "\n",
    "# Fix annotations directory similarly\n",
    "if os.path.isdir(os.path.join(ANNOTATIONS_DIR, 'annotations')):\n",
    "    ANNOTATIONS_DIR = os.path.join(ANNOTATIONS_DIR, 'annotations')\n",
    "\n",
    "if os.path.isdir(os.path.join(ANNOTATIONS_DIR, 'annotations')):\n",
    "    ANNOTATIONS_DIR = os.path.join(ANNOTATIONS_DIR, 'annotations')\n",
    "\n",
    "print(\"Using IMAGES_DIR:\", IMAGES_DIR)\n",
    "print(\"Using ANNOTATIONS_DIR:\", ANNOTATIONS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "1d5a650c-ea02-4756-b985-f2d5c6ef22e4",
    "_uuid": "dd918789-4c5b-463b-a758-bf4060cca0eb",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:26.694224Z",
     "iopub.status.busy": "2025-11-08T10:30:26.693727Z",
     "iopub.status.idle": "2025-11-08T10:30:34.866542Z",
     "shell.execute_reply": "2025-11-08T10:30:34.865923Z",
     "shell.execute_reply.started": "2025-11-08T10:30:26.694205Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples parsed from trainval.txt: 3680\n"
     ]
    }
   ],
   "source": [
    "file_list = []\n",
    "with open(trainval_path, 'r') as f:\n",
    "    lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "for ln in lines:\n",
    "    tokens = ln.split()\n",
    "    if len(tokens) == 0:\n",
    "        continue\n",
    "    img_name = tokens[0]\n",
    "    class_id = int(tokens[1]) - 1 if len(tokens) > 1 else None\n",
    "    image_path = os.path.join(IMAGES_DIR, img_name + '.jpg')\n",
    "    # mask / trimap path lives under \"annotations/trimaps\" and is named <img_name>.png\n",
    "    trimap_path = os.path.join(ANNOTATIONS_DIR, 'trimaps', img_name + '.png')\n",
    "    # fallback if extension is .jpg or .jpeg or .PNG etc.\n",
    "    if not os.path.isfile(image_path):\n",
    "        alt = None\n",
    "        for ext in ['.jpg', '.jpeg', '.png']:\n",
    "            altp = os.path.join(IMAGES_DIR, img_name + ext)\n",
    "            if os.path.isfile(altp):\n",
    "                alt = altp; break\n",
    "        if alt is None:\n",
    "            raise FileNotFoundError(f\"Image {img_name} not found under {IMAGES_DIR}\")\n",
    "        image_path = alt\n",
    "    if not os.path.isfile(trimap_path):\n",
    "        # try alternate locations (some datasets use 'annotations' root directly)\n",
    "        alt_trim = os.path.join(ANNOTATIONS_DIR, img_name + '.png')\n",
    "        if os.path.isfile(alt_trim):\n",
    "            trimap_path = alt_trim\n",
    "        else:\n",
    "            # mask might be missing for some datasets; we won't crash but set None\n",
    "            trimap_path = None\n",
    "\n",
    "    file_list.append({\n",
    "        'image_name': img_name,\n",
    "        'image_path': image_path,\n",
    "        'trimap_path': trimap_path,\n",
    "        'class_id': class_id\n",
    "    })\n",
    "\n",
    "print(f\"Total examples parsed from trainval.txt: {len(file_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "6c9359d3-12fc-4ef6-bb10-82b0353deec1",
    "_uuid": "6f88c323-247a-42e5-ae11-c4609f15c88e",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:34.868236Z",
     "iopub.status.busy": "2025-11-08T10:30:34.868025Z",
     "iopub.status.idle": "2025-11-08T10:30:34.879272Z",
     "shell.execute_reply": "2025-11-08T10:30:34.878567Z",
     "shell.execute_reply.started": "2025-11-08T10:30:34.868220Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes -> train: 2944 val: 736\n",
      "Loading split metadata...\n",
      "✓ Split loaded:\n",
      "  Train indices: 2944\n",
      "  Val indices: 736\n",
      "  Total: 3680\n",
      "✓ Split indices validated\n"
     ]
    }
   ],
   "source": [
    "# Load your split metadata (expects indices relative to the file_list ordering)\n",
    "SPLIT_METADATA = os.path.join(DATASET_ROOT, 'split_metadata.json')\n",
    "if not os.path.isfile(SPLIT_METADATA):\n",
    "    raise FileNotFoundError(\"split_metadata.json not found at: \" + SPLIT_METADATA)\n",
    "\n",
    "with open(SPLIT_METADATA, 'r') as f:\n",
    "    split_info = json.load(f)\n",
    "train_indices = split_info['train_indices']\n",
    "val_indices = split_info['val_indices']\n",
    "print(\"Split sizes -> train:\", len(train_indices), \"val:\", len(val_indices))\n",
    "assert max(train_indices) < len(file_list) and max(val_indices) < len(file_list), \"Split indices exceed dataset length\"\n",
    "# Cell 4: Load Split Metadata\n",
    "print(\"Loading split metadata...\")\n",
    "\n",
    "with open(SPLIT_METADATA, 'r') as f:\n",
    "    split_info = json.load(f)\n",
    "\n",
    "train_indices = split_info['train_indices']\n",
    "val_indices = split_info['val_indices']\n",
    "\n",
    "print(f\"✓ Split loaded:\")\n",
    "print(f\"  Train indices: {len(train_indices)}\")\n",
    "print(f\"  Val indices: {len(val_indices)}\")\n",
    "print(f\"  Total: {len(train_indices) + len(val_indices)}\")\n",
    "\n",
    "# Verify indices are valid\n",
    "assert max(train_indices) < len(file_list), \"Invalid train index\"\n",
    "assert max(val_indices) < len(file_list), \"Invalid val index\"\n",
    "assert len(set(train_indices) & set(val_indices)) == 0, \"Overlap between train and val\"\n",
    "print(\"✓ Split indices validated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "1c1acf5a-71ac-4599-8b6c-977cfca9c98e",
    "_uuid": "794df21a-0cf9-44bc-9278-8049cda0275d",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:34.880246Z",
     "iopub.status.busy": "2025-11-08T10:30:34.880011Z",
     "iopub.status.idle": "2025-11-08T10:30:34.892164Z",
     "shell.execute_reply": "2025-11-08T10:30:34.891537Z",
     "shell.execute_reply.started": "2025-11-08T10:30:34.880229Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ---- Transforms (re-using yours) ----\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.RandomRotation(degrees=10),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "val_transform = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "e1c102bd-1109-44fa-b2f8-32def08121b3",
    "_uuid": "650e8208-be65-493e-bb9f-a0c4d39a3a0b",
    "collapsed": false,
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:34.893191Z",
     "iopub.status.busy": "2025-11-08T10:30:34.892961Z",
     "iopub.status.idle": "2025-11-08T10:30:34.907459Z",
     "shell.execute_reply": "2025-11-08T10:30:34.906768Z",
     "shell.execute_reply.started": "2025-11-08T10:30:34.893166Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Custom file-list dataset class ready\n"
     ]
    }
   ],
   "source": [
    "# ---- Custom dataset class (does not rely on torchvision OxfordIIITPet) ----\n",
    "class OxfordPetFileList(Dataset):\n",
    "    def __init__(self, file_list, indices, transform=None, include_metadata=False):\n",
    "        \"\"\"\n",
    "        file_list: list of dicts with keys 'image_path','trimap_path','class_id'\n",
    "        indices: list of ints referencing positions in file_list\n",
    "        \"\"\"\n",
    "        self._file_list = file_list\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "        self.include_metadata = include_metadata\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        rec = self._file_list[actual_idx]\n",
    "\n",
    "        # Load image\n",
    "        img = Image.open(rec['image_path']).convert('RGB')\n",
    "\n",
    "        # Load mask/trimap if exists (keep as single channel)\n",
    "        mask = None\n",
    "        if rec['trimap_path'] and os.path.isfile(rec['trimap_path']):\n",
    "            mask = Image.open(rec['trimap_path'])\n",
    "            # convert to 'L' to ensure single channel numeric values\n",
    "            mask = mask.convert('L')\n",
    "\n",
    "        # Save original metadata if requested\n",
    "        original_image = np.array(img, dtype=np.uint8) if self.include_metadata else None\n",
    "        original_mask  = np.array(mask, dtype=np.uint8) if (self.include_metadata and mask is not None) else None\n",
    "\n",
    "        # Apply transforms (to the image only)\n",
    "        if self.transform:\n",
    "            img_t = self.transform(img)\n",
    "        else:\n",
    "            img_t = T.ToTensor()(img)\n",
    "\n",
    "        label = rec['class_id']\n",
    "        sample = {\n",
    "            'image': img_t,\n",
    "            'label': label,\n",
    "            'index': actual_idx\n",
    "        }\n",
    "        if self.include_metadata:\n",
    "            sample['original_image'] = original_image\n",
    "            sample['original_mask'] = original_mask\n",
    "\n",
    "        return sample\n",
    "\n",
    "print(\"✓ Custom file-list dataset class ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:34.908320Z",
     "iopub.status.busy": "2025-11-08T10:30:34.908139Z",
     "iopub.status.idle": "2025-11-08T10:30:36.640095Z",
     "shell.execute_reply": "2025-11-08T10:30:36.639246Z",
     "shell.execute_reply.started": "2025-11-08T10:30:34.908305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders created:\n",
      " - train batches: 92\n",
      " - val batches:   23\n",
      "Sanity batch keys: ['image', 'label', 'index']\n",
      "Image tensor shape: torch.Size([32, 3, 224, 224])\n",
      "Label tensor sample: tensor([19, 18, 31, 28, 12, 17, 15, 27])\n"
     ]
    }
   ],
   "source": [
    "# ---- Create dataset & dataloaders ----\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "\n",
    "train_dataset = OxfordPetFileList(file_list=file_list, indices=train_indices, transform=train_transform, include_metadata=False)\n",
    "val_dataset   = OxfordPetFileList(file_list=file_list, indices=val_indices, transform=val_transform, include_metadata=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "print(\"Loaders created:\")\n",
    "print(\" - train batches:\", len(train_loader))\n",
    "print(\" - val batches:  \", len(val_loader))\n",
    "\n",
    "# ---- Quick sanity check: iterate one batch ----\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bs = next(iter(train_loader))\n",
    "print(\"Sanity batch keys:\", list(bs.keys()))\n",
    "print(\"Image tensor shape:\", bs['image'].shape)\n",
    "print(\"Label tensor sample:\", bs['label'][:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T10:30:36.641442Z",
     "iopub.status.busy": "2025-11-08T10:30:36.641188Z",
     "iopub.status.idle": "2025-11-08T10:41:09.225879Z",
     "shell.execute_reply": "2025-11-08T10:41:09.224971Z",
     "shell.execute_reply.started": "2025-11-08T10:30:36.641417Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING: ResNet-50\n",
      "======================================================================\n",
      "✓ ResNet-50 loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: Train Acc=69.7% | Val Acc=82.5%\n",
      "  ✓ Best model saved (Val Acc: 82.47%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: Train Acc=88.2% | Val Acc=88.5%\n",
      "  ✓ Best model saved (Val Acc: 88.45%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: Train Acc=93.0% | Val Acc=87.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: Train Acc=93.9% | Val Acc=86.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: Train Acc=95.0% | Val Acc=87.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: Train Acc=96.6% | Val Acc=87.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: Train Acc=95.7% | Val Acc=88.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: Train Acc=97.6% | Val Acc=89.8%\n",
      "  ✓ Best model saved (Val Acc: 89.81%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: Train Acc=97.9% | Val Acc=84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: Train Acc=98.4% | Val Acc=89.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: Train Acc=99.0% | Val Acc=88.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: Train Acc=99.0% | Val Acc=91.0%\n",
      "  ✓ Best model saved (Val Acc: 91.03%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: Train Acc=99.5% | Val Acc=92.4%\n",
      "  ✓ Best model saved (Val Acc: 92.39%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: Train Acc=98.9% | Val Acc=90.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: Train Acc=99.2% | Val Acc=91.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: Train Acc=99.8% | Val Acc=92.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: Train Acc=99.4% | Val Acc=91.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: Train Acc=99.3% | Val Acc=91.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: Train Acc=99.8% | Val Acc=92.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: Train Acc=99.9% | Val Acc=92.5%\n",
      "  ✓ Best model saved (Val Acc: 92.53%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: Train Acc=99.9% | Val Acc=92.7%\n",
      "  ✓ Best model saved (Val Acc: 92.66%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: Train Acc=99.9% | Val Acc=92.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: Train Acc=99.9% | Val Acc=92.8%\n",
      "  ✓ Best model saved (Val Acc: 92.80%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: Train Acc=99.9% | Val Acc=92.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: Train Acc=100.0% | Val Acc=92.9%\n",
      "  ✓ Best model saved (Val Acc: 92.93%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: Train Acc=99.9% | Val Acc=93.5%\n",
      "  ✓ Best model saved (Val Acc: 93.48%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: Train Acc=100.0% | Val Acc=93.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: Train Acc=100.0% | Val Acc=93.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: Train Acc=100.0% | Val Acc=92.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: Train Acc=100.0% | Val Acc=93.6%\n",
      "  ✓ Best model saved (Val Acc: 93.61%)\n",
      "\n",
      "======================================================================\n",
      "✅ ResNet-50 TRAINING COMPLETE\n",
      "  Time: 10.5 minutes\n",
      "  Best Val Acc: 93.61%\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: RETRAIN - ResNet-50\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING: ResNet-50\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_key = 'resnet50'\n",
    "model_name = 'ResNet-50'\n",
    "\n",
    "LEARNING_RATE = 3e-4      # You can adjust this based on your model\n",
    "WEIGHT_DECAY = 1e-2     # Common default value\n",
    "EPOCHS = 30 \n",
    "BATCH_SIZE = 64\n",
    "# Create model\n",
    "model = models.resnet50(weights='DEFAULT')\n",
    "model.fc = nn.Linear(model.fc.in_features, 37)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"✓ {model_name} loaded\")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [TRAIN]', leave=False)\n",
    "    for batch in pbar:\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{train_loss/(train_total//BATCH_SIZE+1):.4f}', \n",
    "                         'acc': f'{100*train_correct/train_total:.1f}%'})\n",
    "    \n",
    "    epoch_train_loss = train_loss / len(train_loader)\n",
    "    epoch_train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [VAL]', leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{val_loss/(val_total//BATCH_SIZE+1):.4f}',\n",
    "                             'acc': f'{100*val_correct/val_total:.1f}%'})\n",
    "    \n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_val_acc = val_correct / val_total\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['train_acc'].append(epoch_train_acc)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['val_acc'].append(epoch_val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: Train Acc={epoch_train_acc*100:.1f}% | Val Acc={epoch_val_acc*100:.1f}%\")\n",
    "    \n",
    "    # Save best\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        checkpoint_dir = f'/kaggle/working/checkpoints/{model_key}'\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, f'{checkpoint_dir}/best.pth')\n",
    "        \n",
    "        print(f\"  ✓ Best model saved (Val Acc: {best_val_acc*100:.2f}%)\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✅ ResNet-50 TRAINING COMPLETE\")\n",
    "print(f\"  Time: {total_time/60:.1f} minutes\")\n",
    "print(f\"  Best Val Acc: {best_val_acc*100:.2f}%\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T11:31:14.434313Z",
     "iopub.status.busy": "2025-11-08T11:31:14.433987Z",
     "iopub.status.idle": "2025-11-08T11:44:36.477703Z",
     "shell.execute_reply": "2025-11-08T11:44:36.476844Z",
     "shell.execute_reply.started": "2025-11-08T11:31:14.434281Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING: Swin-Tiny\n",
      "======================================================================\n",
      "✓ Swin-Tiny loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: Train Acc=68.3% | Val Acc=78.5%\n",
      "  ✓ Best model saved (Val Acc: 78.53%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: Train Acc=84.4% | Val Acc=84.2%\n",
      "  ✓ Best model saved (Val Acc: 84.24%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: Train Acc=89.1% | Val Acc=85.7%\n",
      "  ✓ Best model saved (Val Acc: 85.73%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: Train Acc=92.2% | Val Acc=87.6%\n",
      "  ✓ Best model saved (Val Acc: 87.64%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: Train Acc=93.3% | Val Acc=83.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: Train Acc=93.1% | Val Acc=85.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: Train Acc=95.3% | Val Acc=85.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: Train Acc=96.5% | Val Acc=88.3%\n",
      "  ✓ Best model saved (Val Acc: 88.32%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: Train Acc=97.1% | Val Acc=88.5%\n",
      "  ✓ Best model saved (Val Acc: 88.45%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: Train Acc=98.0% | Val Acc=88.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: Train Acc=97.0% | Val Acc=85.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: Train Acc=98.7% | Val Acc=89.5%\n",
      "  ✓ Best model saved (Val Acc: 89.54%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: Train Acc=98.6% | Val Acc=87.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: Train Acc=99.4% | Val Acc=90.1%\n",
      "  ✓ Best model saved (Val Acc: 90.08%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: Train Acc=99.5% | Val Acc=89.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: Train Acc=98.2% | Val Acc=89.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: Train Acc=99.4% | Val Acc=89.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: Train Acc=99.7% | Val Acc=89.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: Train Acc=99.8% | Val Acc=90.9%\n",
      "  ✓ Best model saved (Val Acc: 90.90%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: Train Acc=99.9% | Val Acc=90.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: Train Acc=99.9% | Val Acc=90.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: Train Acc=99.9% | Val Acc=91.7%\n",
      "  ✓ Best model saved (Val Acc: 91.71%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: Train Acc=99.9% | Val Acc=91.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: Train Acc=100.0% | Val Acc=91.8%\n",
      "  ✓ Best model saved (Val Acc: 91.85%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: Train Acc=99.9% | Val Acc=91.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: Train Acc=99.9% | Val Acc=91.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: Train Acc=99.8% | Val Acc=91.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: Train Acc=99.9% | Val Acc=91.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: Train Acc=100.0% | Val Acc=91.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: Train Acc=99.8% | Val Acc=91.3%\n",
      "\n",
      "======================================================================\n",
      "✅ Swin-Tiny TRAINING COMPLETE\n",
      "  Time: 13.3 minutes\n",
      "  Best Epoch: 24\n",
      "  Best Val Acc: 91.85%\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.998981</td>\n",
       "      <td>0.364574</td>\n",
       "      <td>0.918478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.997962</td>\n",
       "      <td>0.364238</td>\n",
       "      <td>0.910326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>0.999321</td>\n",
       "      <td>0.357687</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.357777</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>0.355736</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  train_acc  val_loss   val_acc\n",
       "25     26    0.006181   0.998981  0.364574  0.918478\n",
       "26     27    0.005690   0.997962  0.364238  0.910326\n",
       "27     28    0.004878   0.999321  0.357687  0.913043\n",
       "28     29    0.001845   1.000000  0.357777  0.913043\n",
       "29     30    0.005150   0.998302  0.355736  0.913043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 2: RETRAIN - Swin-Tiny (FIXED)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING: Swin-Tiny\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_key = 'swin_tiny'\n",
    "model_name = 'Swin-Tiny'\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-2\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 48\n",
    "\n",
    "# Create model\n",
    "model = timm.create_model(\n",
    "    'swin_tiny_patch4_window7_224',\n",
    "    pretrained=True,\n",
    "    num_classes=37  # ensures correct classification head\n",
    ").to(device)\n",
    "\n",
    "print(f\"✓ {model_name} loaded\")\n",
    "\n",
    "# Optimizer, scheduler, loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_epoch = 0\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [TRAIN]', leave=False)\n",
    "    for batch in pbar:\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        # 🔧 Fix for 4D output (apply global avg pooling if needed)\n",
    "        if outputs.dim() == 4:\n",
    "            outputs = outputs.mean(dim=[2, 3])\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{train_loss/(train_total//BATCH_SIZE+1):.4f}',\n",
    "            'acc': f'{100*train_correct/train_total:.1f}%'\n",
    "        })\n",
    "\n",
    "    epoch_train_loss = train_loss / len(train_loader)\n",
    "    epoch_train_acc = train_correct / train_total\n",
    "\n",
    "    # -------------------- Validation --------------------\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [VAL]', leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # 🔧 again ensure output is 2D\n",
    "            if outputs.dim() == 4:\n",
    "                outputs = outputs.mean(dim=[2, 3])\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{val_loss/(val_total//BATCH_SIZE+1):.4f}',\n",
    "                'acc': f'{100*val_correct/val_total:.1f}%'\n",
    "            })\n",
    "\n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_val_acc = val_correct / val_total\n",
    "    scheduler.step()\n",
    "\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['train_acc'].append(epoch_train_acc)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['val_acc'].append(epoch_val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: \"\n",
    "          f\"Train Acc={epoch_train_acc*100:.1f}% | Val Acc={epoch_val_acc*100:.1f}%\")\n",
    "\n",
    "    # Save best model\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        best_epoch = epoch + 1\n",
    "        checkpoint_dir = f'/kaggle/working/checkpoints/{model_key}'\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, f'{checkpoint_dir}/best.pth')\n",
    "        print(f\"  ✓ Best model saved (Val Acc: {best_val_acc*100:.2f}%)\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✅ Swin-Tiny TRAINING COMPLETE\")\n",
    "print(f\"  Time: {total_time/60:.1f} minutes\")\n",
    "print(f\"  Best Epoch: {best_epoch}\")\n",
    "print(f\"  Best Val Acc: {best_val_acc*100:.2f}%\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Summary Table\n",
    "import pandas as pd\n",
    "summary = pd.DataFrame(history)\n",
    "display(summary.tail())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2025-11-08T12:10:53.381093Z",
     "iopub.status.busy": "2025-11-08T12:10:53.379657Z",
     "iopub.status.idle": "2025-11-08T12:21:43.217240Z",
     "shell.execute_reply": "2025-11-08T12:21:43.216459Z",
     "shell.execute_reply.started": "2025-11-08T12:10:53.381061Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING: DeiT-Small\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6220239e3a2f44e59bf1cc240d674c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ DeiT-Small loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: Train Acc=69.1% | Val Acc=84.2%\n",
      "  ✓ Best model saved (Val Acc: 84.24%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: Train Acc=88.0% | Val Acc=80.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: Train Acc=89.8% | Val Acc=81.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: Train Acc=93.3% | Val Acc=84.8%\n",
      "  ✓ Best model saved (Val Acc: 84.78%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: Train Acc=92.9% | Val Acc=82.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: Train Acc=93.2% | Val Acc=82.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: Train Acc=96.7% | Val Acc=83.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: Train Acc=97.0% | Val Acc=84.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: Train Acc=99.2% | Val Acc=84.9%\n",
      "  ✓ Best model saved (Val Acc: 84.92%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: Train Acc=98.2% | Val Acc=82.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: Train Acc=97.4% | Val Acc=85.3%\n",
      "  ✓ Best model saved (Val Acc: 85.33%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: Train Acc=98.9% | Val Acc=88.0%\n",
      "  ✓ Best model saved (Val Acc: 88.04%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: Train Acc=99.6% | Val Acc=87.6%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: Train Acc=99.5% | Val Acc=85.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: Train Acc=99.6% | Val Acc=90.1%\n",
      "  ✓ Best model saved (Val Acc: 90.08%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: Train Acc=99.8% | Val Acc=89.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: Train Acc=100.0% | Val Acc=88.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: Train Acc=99.9% | Val Acc=89.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: Train Acc=100.0% | Val Acc=89.4%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: Train Acc=100.0% | Val Acc=89.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: Train Acc=100.0% | Val Acc=90.1%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: Train Acc=100.0% | Val Acc=90.4%\n",
      "  ✓ Best model saved (Val Acc: 90.35%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: Train Acc=100.0% | Val Acc=90.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: Train Acc=100.0% | Val Acc=89.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: Train Acc=100.0% | Val Acc=89.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: Train Acc=100.0% | Val Acc=90.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: Train Acc=100.0% | Val Acc=90.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: Train Acc=100.0% | Val Acc=90.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: Train Acc=100.0% | Val Acc=90.8%\n",
      "  ✓ Best model saved (Val Acc: 90.76%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: Train Acc=100.0% | Val Acc=90.8%\n",
      "\n",
      "======================================================================\n",
      "✅ DeiT-Small TRAINING COMPLETE\n",
      "  Time: 10.7 minutes\n",
      "  Best Val Acc: 90.76%\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: RETRAIN - DeiT-Small\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING: DeiT-Small\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_key = 'deit_small'\n",
    "model_name = 'DeiT-Small'\n",
    "\n",
    "LEARNING_RATE = 3e-4      # You can adjust this based on your model\n",
    "WEIGHT_DECAY = 1e-2       # Common default value\n",
    "EPOCHS = 30 \n",
    "BATCH_SIZE = 48\n",
    "\n",
    "# Create model\n",
    "model = timm.create_model('deit_small_patch16_224', pretrained=True)\n",
    "model.head = nn.Linear(model.head.in_features, 37)\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"✓ {model_name} loaded\")\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training\n",
    "history = {\n",
    "    'epoch': [],\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': []\n",
    "}\n",
    "\n",
    "best_val_acc = 0.0\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [TRAIN]', leave=False)\n",
    "    for batch in pbar:\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{train_loss/(train_total//BATCH_SIZE+1):.4f}', \n",
    "                         'acc': f'{100*train_correct/train_total:.1f}%'})\n",
    "    \n",
    "    epoch_train_loss = train_loss / len(train_loader)\n",
    "    epoch_train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [VAL]', leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{val_loss/(val_total//BATCH_SIZE+1):.4f}',\n",
    "                             'acc': f'{100*val_correct/val_total:.1f}%'})\n",
    "    \n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_val_acc = val_correct / val_total\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    history['epoch'].append(epoch + 1)\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['train_acc'].append(epoch_train_acc)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['val_acc'].append(epoch_val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: Train Acc={epoch_train_acc*100:.1f}% | Val Acc={epoch_val_acc*100:.1f}%\")\n",
    "    \n",
    "    # Save best\n",
    "    if epoch_val_acc > best_val_acc:\n",
    "        best_val_acc = epoch_val_acc\n",
    "        checkpoint_dir = f'/kaggle/working/checkpoints/{model_key}'\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'history': history\n",
    "        }, f'{checkpoint_dir}/best.pth')\n",
    "        \n",
    "        print(f\"  ✓ Best model saved (Val Acc: {best_val_acc*100:.2f}%)\")\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"✅ DeiT-Small TRAINING COMPLETE\")\n",
    "print(f\"  Time: {total_time/60:.1f} minutes\")\n",
    "print(f\"  Best Val Acc: {best_val_acc*100:.2f}%\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2025-11-08T10:41:13.972413Z",
     "iopub.status.idle": "2025-11-08T10:41:13.972634Z",
     "shell.execute_reply": "2025-11-08T10:41:13.972544Z",
     "shell.execute_reply.started": "2025-11-08T10:41:13.972535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 4: Verify Training Completed\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ TRAINING COMPLETE - VERIFYING CHECKPOINTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "models_to_check = ['resnet50', 'swin_tiny', 'deit_small']\n",
    "\n",
    "for model_key in models_to_check:\n",
    "    checkpoint_path = f'/kaggle/working/checkpoints/{model_key}/best.pth'\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        size = os.path.getsize(checkpoint_path) / 1e6\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        best_acc = checkpoint.get('best_val_acc', 'N/A')\n",
    "        \n",
    "        print(f\"✓ {model_key}\")\n",
    "        print(f\"  Path: {checkpoint_path}\")\n",
    "        print(f\"  Size: {size:.1f} MB\")\n",
    "        print(f\"  Best Acc: {best_acc*100:.2f}%\" if isinstance(best_acc, float) else f\"  Best Acc: {best_acc}\")\n",
    "    else:\n",
    "        print(f\"✗ {model_key} - NOT FOUND\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Ready for Day 5: Grad-CAM, FAR, and ∆Acc computation!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2025-11-08T10:41:13.973330Z",
     "iopub.status.idle": "2025-11-08T10:41:13.973608Z",
     "shell.execute_reply": "2025-11-08T10:41:13.973502Z",
     "shell.execute_reply.started": "2025-11-08T10:41:13.973486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import py\n",
    "# Cell 15: Plot Training Curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (model_key, result) in enumerate(all_results.items()):\n",
    "    ax = axes[idx]\n",
    "    epochs = result['history']['epoch']\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    ax.plot(epochs, np.array(result['history']['train_acc'])*100, \n",
    "            label='Train', marker='o', markersize=3, linewidth=1.5, color='blue')\n",
    "    ax.plot(epochs, np.array(result['history']['val_acc'])*100, \n",
    "            label='Val', marker='s', markersize=3, linewidth=1.5, color='red')\n",
    "    \n",
    "    # Mark best epoch\n",
    "    best_epoch = np.argmax(result['history']['val_acc']) + 1\n",
    "    best_acc = result['history']['val_acc'][best_epoch - 1]\n",
    "    ax.axvline(x=best_epoch, color='green', linestyle='--', alpha=0.5, linewidth=1.5)\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_title(f\"{result['name']}\\nBest: {best_acc*100:.1f}% @ Epoch {best_epoch}\", \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Epoch', fontsize=10)\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=10)\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.legend(fontsize=9, loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Baseline Model Training Curves\\nResNet-50 vs Swin-Tiny vs DeiT-Small vs ConvNeXt-Tiny', \n",
    "             fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/kaggle/working/results/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training curves saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2025-11-08T10:41:13.974322Z",
     "iopub.status.idle": "2025-11-08T10:41:13.974626Z",
     "shell.execute_reply": "2025-11-08T10:41:13.974485Z",
     "shell.execute_reply.started": "2025-11-08T10:41:13.974471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 16: Save Detailed Results\n",
    "import json\n",
    "\n",
    "print(\"Saving training histories...\\n\")\n",
    "\n",
    "# Save each model's history as CSV\n",
    "for model_key, result in all_results.items():\n",
    "    history_df = pd.DataFrame({\n",
    "        'epoch': result['history']['epoch'],\n",
    "        'train_loss': result['history']['train_loss'],\n",
    "        'train_acc': result['history']['train_acc'],\n",
    "        'val_loss': result['history']['val_loss'],\n",
    "        'val_acc': result['history']['val_acc'],\n",
    "        'lr': result['history']['lr']\n",
    "    })\n",
    "    \n",
    "    history_path = f'/kaggle/working/results/{model_key}_history.csv'\n",
    "    history_df.to_csv(history_path, index=False)\n",
    "    print(f\"✓ Saved: {model_key}_history.csv\")\n",
    "\n",
    "# Save summary JSON\n",
    "summary = {\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'total_epochs': EPOCHS,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "    'models': {}\n",
    "}\n",
    "\n",
    "for model_key, result in all_results.items():\n",
    "    best_epoch = np.argmax(result['history']['val_acc']) + 1\n",
    "    summary['models'][model_key] = {\n",
    "        'name': result['name'],\n",
    "        'best_val_acc': float(result['best_acc']),\n",
    "        'best_epoch': int(best_epoch),\n",
    "        'final_train_acc': float(result['history']['train_acc'][-1]),\n",
    "        'final_val_acc': float(result['history']['val_acc'][-1])\n",
    "    }\n",
    "\n",
    "with open('/kaggle/working/results/summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Saved: summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2025-11-08T10:41:13.975704Z",
     "iopub.status.idle": "2025-11-08T10:41:13.975923Z",
     "shell.execute_reply": "2025-11-08T10:41:13.975831Z",
     "shell.execute_reply.started": "2025-11-08T10:41:13.975822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell 17: Training Complete Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ TRAINING PIPELINE COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nResults saved to /kaggle/working/results/:\")\n",
    "for file in sorted(os.listdir('/kaggle/working/results/')):\n",
    "    file_path = f'/kaggle/working/results/{file}'\n",
    "    file_size = os.path.getsize(file_path) / 1e6\n",
    "    print(f\"  ✓ {file} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(\"\\nModel checkpoints saved to /kaggle/working/checkpoints/:\")\n",
    "for model in sorted(os.listdir('/kaggle/working/checkpoints/')):\n",
    "    ckpt_path = f'/kaggle/working/checkpoints/{model}/best.pth'\n",
    "    if os.path.exists(ckpt_path):\n",
    "        ckpt_size = os.path.getsize(ckpt_path) / 1e6\n",
    "        print(f\"  ✓ {model}/best.pth ({ckpt_size:.1f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY RESULTS:\")\n",
    "print(\"=\"*70)\n",
    "for model_key, result in all_results.items():\n",
    "    best_epoch = np.argmax(result['history']['val_acc']) + 1\n",
    "    print(f\"\\n{result['name']}:\")\n",
    "    print(f\"  Best validation accuracy: {result['best_acc']*100:.2f}%\")\n",
    "    print(f\"  Best epoch: {best_epoch}\")\n",
    "    print(f\"  Final train accuracy: {result['history']['train_acc'][-1]*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.status.busy": "2025-11-08T10:41:13.976980Z",
     "iopub.status.idle": "2025-11-08T10:41:13.977300Z",
     "shell.execute_reply": "2025-11-08T10:41:13.977144Z",
     "shell.execute_reply.started": "2025-11-08T10:41:13.977131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Cell: Check for Existing Checkpoints\n",
    "\n",
    "import os\n",
    "\n",
    "checkpoint_dir = '/kaggle/working/checkpoints'\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"✓ Checkpoints directory exists!\\n\")\n",
    "    \n",
    "    models_found = {}\n",
    "    for model_name in ['resnet50', 'swin_tiny', 'deit_small', 'convnext_tiny']:\n",
    "        model_dir = os.path.join(checkpoint_dir, model_name)\n",
    "        if os.path.exists(model_dir):\n",
    "            best_pth = os.path.join(model_dir, 'best.pth')\n",
    "            if os.path.exists(best_pth):\n",
    "                size = os.path.getsize(best_pth) / 1e6  # MB\n",
    "                models_found[model_name] = size\n",
    "                print(f\"✓ {model_name}: {size:.1f} MB\")\n",
    "            else:\n",
    "                print(f\"✗ {model_name}: Directory exists but no best.pth\")\n",
    "        else:\n",
    "            print(f\"✗ {model_name}: Directory not found\")\n",
    "    \n",
    "    if len(models_found) == 4:\n",
    "        print(f\"\\n✅ ALL 4 MODELS FOUND! ({sum(models_found.values()):.0f} MB total)\")\n",
    "        print(\"   You can download and continue!\")\n",
    "    else:\n",
    "        print(f\"\\n⚠️  Only {len(models_found)}/4 models found - retrain needed\")\n",
    "else:\n",
    "    print(\"❌ Checkpoints directory does not exist - need to retrain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Grad-CAM Analysis for All 3 Models (ResNet-50, Swin-Tiny, DeiT-Small)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRAD-CAM ANALYSIS - ALL 3 MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTION: COMPUTE FAR (Foreground Attention Ratio)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_far(cam, mask):\n",
    "    \"\"\"\n",
    "    Compute Foreground Attention Ratio\n",
    "    \n",
    "    Args:\n",
    "        cam: Grad-CAM activation map (normalized 0-1)\n",
    "        mask: Binary segmentation mask (1=foreground, 0=background)\n",
    "    \n",
    "    Returns:\n",
    "        FAR: Fraction of attention on foreground (0-1)\n",
    "    \"\"\"\n",
    "    foreground_attention = cam[mask == 1].sum()\n",
    "    total_attention = cam.sum()\n",
    "    return float(foreground_attention / total_attention) if total_attention > 0 else 0.0\n",
    "\n",
    "# ============================================================================\n",
    "# GET TARGET LAYERS FOR EACH MODEL\n",
    "# ============================================================================\n",
    "\n",
    "def get_target_layer(model, model_key):\n",
    "    \"\"\"Get the appropriate layer for Grad-CAM for each architecture\"\"\"\n",
    "    \n",
    "    if model_key == 'resnet50':\n",
    "        return model.layer4[-1]  # Last residual block\n",
    "    \n",
    "    elif model_key == 'swin_tiny':\n",
    "        # Last stage, last block, first norm layer\n",
    "        return model.layers[-1].blocks[-1].norm1\n",
    "    \n",
    "    elif model_key == 'deit_small':\n",
    "        # Last transformer block, first norm layer\n",
    "        return model.blocks[-1].norm1\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_key}\")\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCTION: COMPUTE GRAD-CAM FOR ONE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "def compute_gradcam_for_model(model, model_key, val_loader_with_masks, device, num_samples=200):\n",
    "    \"\"\"\n",
    "    Compute Grad-CAM and FAR for one model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        model_key: 'resnet50', 'swin_tiny', or 'deit_small'\n",
    "        val_loader_with_masks: DataLoader with original images and masks\n",
    "        device: 'cuda' or 'cpu'\n",
    "        num_samples: Number of validation samples to analyze (200 for speed)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with FAR statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'─'*80}\")\n",
    "    print(f\"Computing Grad-CAM for {model_key.upper()}\")\n",
    "    print(f\"{'─'*80}\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Get target layer\n",
    "    target_layer = get_target_layer(model, model_key)\n",
    "    \n",
    "    # Create Grad-CAM extractor\n",
    "    cam_extractor = GradCAM(model=model, target_layers=[target_layer], use_cuda=(device.type == 'cuda'))\n",
    "    \n",
    "    far_scores = []\n",
    "    predictions_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Process validation samples\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(val_loader_with_masks, desc=f'Computing Grad-CAM', leave=False)):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            masks = batch['mask'].numpy()[0]  # (224, 224)\n",
    "            \n",
    "            # Get model prediction\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            pred_class = predicted.item()\n",
    "            \n",
    "            # Track accuracy\n",
    "            is_correct = (predicted.item() == labels.item())\n",
    "            predictions_correct += is_correct\n",
    "            total_samples += 1\n",
    "            \n",
    "            # Generate Grad-CAM\n",
    "            try:\n",
    "                targets = [ClassifierOutputTarget(pred_class)]\n",
    "                grayscale_cam = cam_extractor(input_tensor=images, targets=targets)[0]\n",
    "                \n",
    "                # Normalize CAM to [0, 1]\n",
    "                cam_min = grayscale_cam.min()\n",
    "                cam_max = grayscale_cam.max()\n",
    "                cam_normalized = (grayscale_cam - cam_min) / (cam_max - cam_min + 1e-8)\n",
    "                \n",
    "                # Compute FAR\n",
    "                far = compute_far(cam_normalized, masks)\n",
    "                far_scores.append(far)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Warning: Grad-CAM failed for sample {i}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Compute statistics\n",
    "    if far_scores:\n",
    "        far_mean = np.mean(far_scores)\n",
    "        far_std = np.std(far_scores)\n",
    "        far_median = np.median(far_scores)\n",
    "        far_min = np.min(far_scores)\n",
    "        far_max = np.max(far_scores)\n",
    "    else:\n",
    "        far_mean = far_std = far_median = far_min = far_max = 0.0\n",
    "    \n",
    "    accuracy = predictions_correct / total_samples if total_samples > 0 else 0.0\n",
    "    \n",
    "    print(f\"\\n  Samples analyzed: {len(far_scores)}\")\n",
    "    print(f\"  Prediction accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"  Mean FAR: {far_mean:.4f} ± {far_std:.4f}\")\n",
    "    print(f\"  Median FAR: {far_median:.4f}\")\n",
    "    print(f\"  Range: [{far_min:.4f}, {far_max:.4f}]\")\n",
    "    \n",
    "    # BDI is inverse of FAR (Background Dependence Index)\n",
    "    bdi_mean = 1 - far_mean\n",
    "    print(f\"  Mean BDI: {bdi_mean:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'model_key': model_key,\n",
    "        'far_mean': far_mean,\n",
    "        'far_std': far_std,\n",
    "        'far_median': far_median,\n",
    "        'far_min': far_min,\n",
    "        'far_max': far_max,\n",
    "        'far_scores': far_scores,\n",
    "        'bdi_mean': bdi_mean,\n",
    "        'accuracy': accuracy,\n",
    "        'samples_analyzed': len(far_scores)\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE VALIDATION LOADER WITH MASKS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nPreparing validation dataset with segmentation masks...\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ValidationDatasetWithMasks(Dataset):\n",
    "    \"\"\"Validation dataset that returns images with their segmentation masks\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dataset, indices, transform=None):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        image, mask = self.base_dataset[actual_idx]\n",
    "        label = self.base_dataset._labels[actual_idx]\n",
    "        \n",
    "        # Resize to 224x224\n",
    "        image = image.resize((224, 224))\n",
    "        mask = mask.resize((224, 224))\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        image_np = np.array(image, dtype=np.float32) / 255.0\n",
    "        mask_np = np.array(mask, dtype=np.uint8)\n",
    "        \n",
    "        # Binary mask (1=pet foreground, 0=background)\n",
    "        binary_mask = (mask_np == 1).astype(np.float32)\n",
    "        \n",
    "        # Apply transform if provided\n",
    "        if self.transform:\n",
    "            image_np = self.transform(image_np)\n",
    "        else:\n",
    "            # Manual normalization\n",
    "            IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "            IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "            image_np = (image_np - np.array(IMAGENET_MEAN)) / np.array(IMAGENET_STD)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        image_tensor = torch.from_numpy(image_np.transpose(2, 0, 1)).float()\n",
    "        \n",
    "        return {\n",
    "            'image': image_tensor,\n",
    "            'mask': binary_mask,\n",
    "            'label': label,\n",
    "            'index': actual_idx\n",
    "        }\n",
    "\n",
    "# Create validation loader with masks\n",
    "val_dataset_with_masks = ValidationDatasetWithMasks(\n",
    "    dataset,\n",
    "    val_indices,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "val_loader_with_masks = DataLoader(\n",
    "    val_dataset_with_masks,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Validation loader created: {len(val_dataset_with_masks)} images\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD TRAINED MODELS AND COMPUTE GRAD-CAM\n",
    "# ============================================================================\n",
    "\n",
    "all_gradcam_results = {}\n",
    "\n",
    "for model_key in ['resnet50', 'swin_tiny', 'deit_small']:\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"LOADING {model_key.upper()} MODEL\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load model\n",
    "    if model_key == 'resnet50':\n",
    "        model = models.resnet50(weights=None)\n",
    "        model.fc = nn.Linear(2048, 37)\n",
    "    \n",
    "    elif model_key == 'swin_tiny':\n",
    "        model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=False)\n",
    "        model.head = nn.Linear(768, 37)\n",
    "    \n",
    "    elif model_key == 'deit_small':\n",
    "        model = timm.create_model('deit_small_patch16_224', pretrained=False)\n",
    "        model.head = nn.Linear(384, 37)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint_path = f'/kaggle/working/checkpoints/{model_key}/best.pth'\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"✓ Model loaded from: {checkpoint_path}\")\n",
    "        print(f\"  Best validation accuracy: {checkpoint.get('best_val_acc', 'N/A')}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"✗ Checkpoint not found: {checkpoint_path}\")\n",
    "        print(f\"  Skipping {model_key}...\")\n",
    "        continue\n",
    "    \n",
    "    model = model.to(device).eval()\n",
    "    \n",
    "    # Compute Grad-CAM\n",
    "    gradcam_result = compute_gradcam_for_model(\n",
    "        model,\n",
    "        model_key,\n",
    "        val_loader_with_masks,\n",
    "        device,\n",
    "        num_samples=200\n",
    "    )\n",
    "    \n",
    "    all_gradcam_results[model_key] = gradcam_result\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# ============================================================================\n",
    "# CREATE RESULTS TABLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRAD-CAM ANALYSIS RESULTS - ALL MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_table = []\n",
    "\n",
    "for model_key, result in all_gradcam_results.items():\n",
    "    results_table.append({\n",
    "        'Model': model_key.replace('_', '-').upper(),\n",
    "        'FAR (Mean±Std)': f\"{result['far_mean']:.4f}±{result['far_std']:.4f}\",\n",
    "        'BDI': f\"{result['bdi_mean']:.4f}\",\n",
    "        'Median FAR': f\"{result['far_median']:.4f}\",\n",
    "        'Range [min, max]': f\"[{result['far_min']:.4f}, {result['far_max']:.4f}]\",\n",
    "        'Accuracy (%)': f\"{result['accuracy']*100:.2f}\",\n",
    "        'Samples': result['samples_analyzed']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results_table)\n",
    "\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "\n",
    "# Save results\n",
    "os.makedirs('/kaggle/working/results', exist_ok=True)\n",
    "results_df.to_csv('/kaggle/working/results/gradcam_far_all_models.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Results saved to: /kaggle/working/results/gradcam_far_all_models.csv\")\n",
    "\n",
    "# ============================================================================\n",
    "# INTERPRETATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for model_key, result in all_gradcam_results.items():\n",
    "    print(f\"\\n{result['model_key'].upper()}:\")\n",
    "    print(f\"  FAR = {result['far_mean']:.4f}\")\n",
    "    print(f\"  → Model focuses {result['far_mean']*100:.1f}% of attention on pet foreground\")\n",
    "    print(f\"  → Model focuses {result['bdi_mean']*100:.1f}% of attention on background\")\n",
    "    \n",
    "    if result['far_mean'] > 0.65:\n",
    "        print(f\"  → ✓ High foreground focus (good sign!)\")\n",
    "    else:\n",
    "        print(f\"  → ⚠ Relatively low foreground focus\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ GRAD-CAM ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNext step: Evaluate models on COUNTERFACTUAL images to test if background\")\n",
    "print(\"information actually influences predictions (compute ∆Acc)\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8671919,
     "sourceId": 13642328,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
